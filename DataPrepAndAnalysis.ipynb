{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale, label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import hmean\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, concatenate, Activation\n",
    "from keras.layers import Flatten, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Train Dataset\n",
    "tweets=pd.read_csv(\"D:/Thesis/Code/Data/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "tok = WordPunctTokenizer()\n",
    "#stop_words = set(stopwords.words('english')) \n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "pat3 = r'RT @[A-Za-z0-9_]+'\n",
    "pat4 = r'RT @[A-Za-z0-9_ ] RT+'\n",
    "#combined_pat = r'|'.join((pat1, pat2,pat3))\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "rt_pattern= re.compile(pat3,flags=re.IGNORECASE)\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    if rt_pattern.match(bom_removed):\n",
    "        rt_stripped=re.sub(pat3,'',bom_removed)\n",
    "        stripped = re.sub(combined_pat, '', rt_stripped)\n",
    "    else:\n",
    "        stripped = re.sub(combined_pat, '', bom_removed)\n",
    "        stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    #tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 525 of 5250 has been processed\n",
      "Tweets 1050 of 5250 has been processed\n",
      "Tweets 1575 of 5250 has been processed\n",
      "Tweets 2100 of 5250 has been processed\n",
      "Tweets 2625 of 5250 has been processed\n",
      "Tweets 3150 of 5250 has been processed\n",
      "Tweets 3675 of 5250 has been processed\n",
      "Tweets 4200 of 5250 has been processed\n",
      "Tweets 4725 of 5250 has been processed\n",
      "Tweets 5250 of 5250 has been processed\n"
     ]
    }
   ],
   "source": [
    "x = len(tweets.index)\n",
    "nums = [0,x]\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%525 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(tweets['text'][i]))\n",
    "    clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['target'] = tweets.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clean_df.text\n",
    "y = clean_df.target\n",
    "SEED = 5\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def labelize_tweets_ug(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\gensim\\models\\doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1643904.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1650187.05it/s]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 07:31:11.659564 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2642200.14it/s]\n",
      "W0818 07:31:11.829520 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1927866.92it/s]\n",
      "W0818 07:31:11.999475 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5262929.25it/s]\n",
      "W0818 07:31:12.177266 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5249128.96it/s]\n",
      "W0818 07:31:12.349336 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2615523.93it/s]\n",
      "W0818 07:31:12.524546 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5261671.68it/s]\n",
      "W0818 07:31:12.701993 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632723.10it/s]\n",
      "W0818 07:31:12.883736 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1305978.06it/s]\n",
      "W0818 07:31:13.059583 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:13.230127 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5262929.25it/s]\n",
      "W0818 07:31:13.399534 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633037.91it/s]\n",
      "W0818 07:31:13.559448 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1017470.47it/s]\n",
      "W0818 07:31:13.745738 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2630835.84it/s]\n",
      "W0818 07:31:13.909679 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1053089.24it/s]\n",
      "W0818 07:31:14.089532 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633667.74it/s]\n",
      "W0818 07:31:14.249486 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1736189.86it/s]\n",
      "W0818 07:31:14.419685 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1305203.96it/s]\n",
      "W0818 07:31:14.599561 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631464.63it/s]\n",
      "W0818 07:31:14.799718 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1735368.90it/s]\n",
      "W0818 07:31:14.974317 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:15.129552 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633352.79it/s]\n",
      "W0818 07:31:15.309700 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633352.79it/s]\n",
      "W0818 07:31:15.508400 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1746517.77it/s]\n",
      "W0818 07:31:15.679506 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 686262.22it/s]\n",
      "W0818 07:31:15.849571 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 993059.26it/s]\n",
      "W0818 07:31:16.019844 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5264187.43it/s]\n",
      "W0818 07:31:16.209746 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5105517.27it/s]\n",
      "W0818 07:31:16.374684 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5146084.60it/s]\n",
      "W0818 07:31:16.539460 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631464.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 07:31:16.709492 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6696315120711563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pure Distributed Bag of Words\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dbow.build_vocab([x for x in tqdm(all_x_w2v)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dbow.alpha -= 0.002\n",
    "    model_ug_dbow.min_alpha = model_ug_dbow.alpha\n",
    "    \n",
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs\n",
    "  \n",
    "train_vecs_dbow = get_vectors(model_ug_dbow, x_train, 100)\n",
    "validation_vecs_dbow = get_vectors(model_ug_dbow, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow, y_train)\n",
    "clf.score(validation_vecs_dbow, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\gensim\\models\\doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1052938.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<?, ?it/s]\n",
      "W0818 07:31:32.743225 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2629265.19it/s]\n",
      "W0818 07:31:33.036234 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5257902.58it/s]\n",
      "W0818 07:31:33.312040 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631779.13it/s]\n",
      "W0818 07:31:33.620216 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633352.79it/s]\n",
      "W0818 07:31:33.899587 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 3483641.20it/s]\n",
      "W0818 07:31:34.189668 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5259158.35it/s]\n",
      "W0818 07:31:34.479655 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1755428.57it/s]\n",
      "W0818 07:31:34.777065 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631464.63it/s]\n",
      "W0818 07:31:35.079561 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1462546.23it/s]\n",
      "W0818 07:31:35.369666 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5264187.43it/s]\n",
      "W0818 07:31:35.639771 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1804630.06it/s]\n",
      "W0818 07:31:35.939451 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1755008.85it/s]\n",
      "W0818 07:31:36.219470 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1316440.25it/s]\n",
      "W0818 07:31:36.459760 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5368136.52it/s]\n",
      "W0818 07:31:36.739776 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633352.79it/s]\n",
      "W0818 07:31:37.019664 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5315012.31it/s]\n",
      "W0818 07:31:37.279463 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5260414.72it/s]\n",
      "W0818 07:31:37.529740 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2567342.43it/s]\n",
      "W0818 07:31:37.827609 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1316597.67it/s]\n",
      "W0818 07:31:38.110833 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1045936.26it/s]\n",
      "W0818 07:31:38.431678 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:38.730918 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5265446.20it/s]\n",
      "W0818 07:31:39.096426 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2630835.84it/s]\n",
      "W0818 07:31:39.339792 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 889413.36it/s]\n",
      "W0818 07:31:39.609825 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5266705.57it/s]\n",
      "W0818 07:31:39.919722 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5267965.55it/s]\n",
      "W0818 07:31:40.199817 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1754729.14it/s]\n",
      "W0818 07:31:40.479591 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633037.91it/s]\n",
      "W0818 07:31:40.819499 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 526267.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 07:31:41.106801 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6467598475222364"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pure Distributed Memory Mean\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmm = Doc2Vec(dm=1, dm_mean=1, size=100, window=4, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmm.build_vocab([x for x in tqdm(all_x_w2v)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmm.alpha -= 0.002\n",
    "    model_ug_dmm.min_alpha = model_ug_dmm.alpha\n",
    "    \n",
    "train_vecs_dmm = get_vectors(model_ug_dmm, x_train, 100)\n",
    "validation_vecs_dmm = get_vectors(model_ug_dmm, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm, y_train)\n",
    "clf.score(validation_vecs_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6696315120711563"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DBOW+DMM\n",
    "def get_concat_vectors(model1,model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix],model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs\n",
    "\n",
    "train_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, x_train, 200)\n",
    "validation_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, x_validation, 200)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmm, y_train)\n",
    "clf.score(validation_vecs_dbow_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1316046.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#Separate Word2Vec\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_cbow = Word2Vec(sg=0, size=100, negative=5, window=2, min_count=2,\n",
    "                         workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_cbow.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1051279.29it/s]\n",
      "W0818 07:31:53.733140 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2570939.40it/s]\n",
      "W0818 07:31:53.778019 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631779.13it/s]\n",
      "W0818 07:31:53.822898 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2589076.54it/s]\n",
      "W0818 07:31:53.871802 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2605928.52it/s]\n",
      "W0818 07:31:53.914685 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:53.960530 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1754589.32it/s]\n",
      "W0818 07:31:54.003448 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631779.13it/s]\n",
      "W0818 07:31:54.049293 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631464.63it/s]\n",
      "W0818 07:31:54.095710 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2630835.84it/s]\n",
      "W0818 07:31:54.139559 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632723.10it/s]\n",
      "W0818 07:31:54.191441 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631464.63it/s]\n",
      "W0818 07:31:54.235334 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1753192.36it/s]\n",
      "W0818 07:31:54.283824 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633037.91it/s]\n",
      "W0818 07:31:54.332694 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633667.74it/s]\n",
      "W0818 07:31:54.377607 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2630835.84it/s]\n",
      "W0818 07:31:54.419492 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632723.10it/s]\n",
      "W0818 07:31:54.467333 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2642517.22it/s]\n",
      "W0818 07:31:54.536695 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1053492.30it/s]\n",
      "W0818 07:31:54.606513 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633037.91it/s]\n",
      "W0818 07:31:54.649398 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:54.694786 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631779.13it/s]\n",
      "W0818 07:31:54.745650 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1755428.57it/s]\n",
      "W0818 07:31:54.791037 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633352.79it/s]\n",
      "W0818 07:31:54.837911 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5266705.57it/s]\n",
      "W0818 07:31:54.879799 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632723.10it/s]\n",
      "W0818 07:31:54.927671 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632723.10it/s]\n",
      "W0818 07:31:54.973549 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631464.63it/s]\n",
      "W0818 07:31:55.016434 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2630835.84it/s]\n",
      "W0818 07:31:55.062311 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632408.37it/s]\n",
      "W0818 07:31:55.106194 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2635243.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 871841.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 07:31:55.286584 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2571840.22it/s]\n",
      "W0818 07:31:55.342433 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2634928.32it/s]\n",
      "W0818 07:31:55.393298 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632723.10it/s]\n",
      "W0818 07:31:55.445159 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:55.498018 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2569739.29it/s]\n",
      "W0818 07:31:55.551065 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632408.37it/s]\n",
      "W0818 07:31:55.601928 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1754030.27it/s]\n",
      "W0818 07:31:55.654787 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2634297.88it/s]\n",
      "W0818 07:31:55.703656 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1748320.44it/s]\n",
      "W0818 07:31:55.759507 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1754449.53it/s]\n",
      "W0818 07:31:55.820345 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633667.74it/s]\n",
      "W0818 07:31:55.889667 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 735646.14it/s]\n",
      "W0818 07:31:55.966654 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1052988.52it/s]\n",
      "W0818 07:31:56.040625 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 590731.19it/s]\n",
      "W0818 07:31:56.104326 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1756408.71it/s]\n",
      "W0818 07:31:56.170678 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2633982.78it/s]\n",
      "W0818 07:31:56.222780 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632408.37it/s]\n",
      "W0818 07:31:56.275639 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5262929.25it/s]\n",
      "W0818 07:31:56.324977 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1755288.64it/s]\n",
      "W0818 07:31:56.374845 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 5266705.57it/s]\n",
      "W0818 07:31:56.423223 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631779.13it/s]\n",
      "W0818 07:31:56.477079 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631150.20it/s]\n",
      "W0818 07:31:56.527943 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2631779.13it/s]\n",
      "W0818 07:31:56.576812 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632723.10it/s]\n",
      "W0818 07:31:56.627676 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:56.684557 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2647919.19it/s]\n",
      "W0818 07:31:56.740376 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1315810.94it/s]\n",
      "W0818 07:31:56.794230 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 2632093.71it/s]\n",
      "W0818 07:31:56.846092 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5250/5250 [00:00<00:00, 1746933.44it/s]\n",
      "W0818 07:31:56.901942 15064 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6581956797966964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6632782719186785\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_ug_cbow.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]),\n",
    "                        total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_cbow.alpha -= 0.002\n",
    "    model_ug_cbow.min_alpha = model_ug_cbow.alpha\n",
    "\n",
    "model_ug_sg = Word2Vec(sg=1, size=100, negative=5, window=2, min_count=2,\n",
    "                       workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_sg.build_vocab([x.words for x in tqdm(all_x_w2v)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_sg.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]),\n",
    "                      total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_sg.alpha -= 0.002\n",
    "    model_ug_sg.min_alpha = model_ug_sg.alpha\n",
    "\n",
    "def get_w2v_mean(tweet, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tweet.split():\n",
    "        try:\n",
    "            vec += np.append(model_ug_cbow[word],model_ug_sg[word]).reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "  \n",
    "def get_w2v_sum(tweet, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    for word in tweet.split():\n",
    "        try:\n",
    "            vec += np.append(model_ug_cbow[word],model_ug_sg[word]).reshape((1, size))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return vec\n",
    "  \n",
    "train_vecs_cbowsg_mean = scale(np.concatenate([get_w2v_mean(z, 200) for z in x_train]))\n",
    "validation_vecs_cbowsg_mean = scale(np.concatenate([get_w2v_mean(z, 200) for z in x_validation]))\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_cbowsg_mean, y_train)\n",
    "print(clf.score(validation_vecs_cbowsg_mean, y_validation))\n",
    "\n",
    "train_vecs_cbowsg_sum = scale(np.concatenate([get_w2v_sum(z, 200) for z in x_train]))\n",
    "validation_vecs_cbowsg_sum = scale(np.concatenate([get_w2v_sum(z, 200) for z in x_validation]))\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_cbowsg_sum, y_train)\n",
    "print(clf.score(validation_vecs_cbowsg_sum, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v general\n",
    "def get_w2v_general(tweet, size, vectors, aggregation='mean'):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tweet.split():\n",
    "        try:\n",
    "            vec += vectors[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if aggregation == 'mean':\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        return vec\n",
    "    elif aggregation == 'sum':\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word vectors extracted from Doc2Vec models with custom weighting\n",
    "cvec = CountVectorizer(max_features=100000)\n",
    "cvec.fit(x_train)\n",
    "\n",
    "neg_train = x_train[y_train == 0]\n",
    "pos_train = x_train[y_train == 1]\n",
    "neu_train = x_train[y_train == 2]\n",
    "neg_doc_matrix = cvec.transform(neg_train)\n",
    "pos_doc_matrix = cvec.transform(pos_train)\n",
    "neu_doc_matrix = cvec.transform(neu_train)\n",
    "neg_tf = np.sum(neg_doc_matrix,axis=0)\n",
    "pos_tf = np.sum(pos_doc_matrix,axis=0)\n",
    "neu_tf = np.sum(neu_doc_matrix,axis=0)\n",
    "\n",
    "def normcdf(x):\n",
    "    return norm.cdf(x, x.mean(), x.std())\n",
    "\n",
    "neg = np.squeeze(np.asarray(neg_tf))\n",
    "pos = np.squeeze(np.asarray(pos_tf))\n",
    "neu = np.squeeze(np.asarray(neu_tf))\n",
    "term_freq_df2 = pd.DataFrame([neg,pos,neu],columns=cvec.get_feature_names()).transpose()\n",
    "term_freq_df2.columns = ['negative', 'positive','neutral']\n",
    "term_freq_df2['total'] = term_freq_df2['negative'] + term_freq_df2['positive'] + term_freq_df2['neutral']\n",
    "term_freq_df2['pos_rate'] = term_freq_df2['positive'] * 1./term_freq_df2['total']\n",
    "term_freq_df2['pos_freq_pct'] = term_freq_df2['positive'] * 1./term_freq_df2['positive'].sum()\n",
    "term_freq_df2['pos_rate_normcdf'] = normcdf(term_freq_df2['pos_rate'])\n",
    "term_freq_df2['pos_freq_pct_normcdf'] = normcdf(term_freq_df2['pos_freq_pct'])\n",
    "term_freq_df2['pos_normcdf_hmean'] = hmean([term_freq_df2['pos_rate_normcdf'], term_freq_df2['pos_freq_pct_normcdf']])\n",
    "pos_hmean = term_freq_df2.pos_normcdf_hmean\n",
    "\n",
    "\n",
    "#w2v_pos_hmean = {}\n",
    "#for w in model_ug_dbow.wv.vocab.keys():\n",
    "#    if w in pos_hmean.keys():\n",
    "#        w2v_pos_hmean[w] = np.append(model_ug_dbow[w],model_ug_dmm[w]) * pos_hmean[w]\n",
    "        \n",
    "#train_vecs_w2v_poshmean_mean = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean, 'mean') for z in x_train]))\n",
    "#validation_vecs_w2v_poshmean_mean = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean, 'mean') for z in x_validation]))\n",
    "#clf = LogisticRegression()\n",
    "#clf.fit(train_vecs_w2v_poshmean_mean, y_train)\n",
    "#print(clf.score(validation_vecs_w2v_poshmean_mean, y_validation))\n",
    "\n",
    "#train_vecs_w2v_poshmean_sum = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean, 'sum') for z in x_train]))\n",
    "#validation_vecs_w2v_poshmean_sum = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean, 'sum') for z in x_validation]))\n",
    "#clf = LogisticRegression()\n",
    "#clf.fit(train_vecs_w2v_poshmean_sum, y_train)\n",
    "#print(clf.score(validation_vecs_w2v_poshmean_sum, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6797966963151207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6810673443456162\n"
     ]
    }
   ],
   "source": [
    "#Separately trained Word2Vec with custom weighting (Average/Sum)\n",
    "w2v_pos_hmean_01 = {}\n",
    "for w in model_ug_cbow.wv.vocab.keys():\n",
    "    if w in pos_hmean.keys():\n",
    "        w2v_pos_hmean_01[w] = np.append(model_ug_cbow[w],model_ug_sg[w]) * pos_hmean[w]\n",
    "        \n",
    "train_vecs_w2v_poshmean_mean_01 = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean_01, 'mean') for z in x_train]))\n",
    "validation_vecs_w2v_poshmean_mean_01 = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean_01, 'mean') for z in x_validation]))\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_w2v_poshmean_mean_01, y_train)\n",
    "print(clf.score(validation_vecs_w2v_poshmean_mean_01, y_validation))\n",
    "\n",
    "train_vecs_w2v_poshmean_sum_01 = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean_01, 'sum') for z in x_train]))\n",
    "validation_vecs_w2v_poshmean_sum_01 = scale(np.concatenate([get_w2v_general(z, 200, w2v_pos_hmean_01, 'sum') for z in x_validation]))\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_w2v_poshmean_sum_01, y_train)\n",
    "print(clf.score(validation_vecs_w2v_poshmean_sum_01, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ug_cbow.save(\"w2v_model_ug_cbow.word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ug_sg.save(\"w2v_model_ug_sg.word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'w2v_model_ug_cbow.word2vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-73ceb30d78ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_ug_cbow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'w2v_model_ug_cbow.word2vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_ug_sg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'w2v_model_ug_sg.word2vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensor\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1540\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1541\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFastTextKeyedVectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1542\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'compatible_hash'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensor\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseKeyedVectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensor\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensor\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m     \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[1;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensor\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensor\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'w2v_model_ug_cbow.word2vec'"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_ug_cbow = KeyedVectors.load('w2v_model_ug_cbow.word2vec')\n",
    "model_ug_sg = KeyedVectors.load('w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model_ug_cbow.wv.vocab.keys():\n",
    "    embeddings_index[w] = np.append(model_ug_cbow.wv[w],model_ug_sg.wv[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_val = tokenizer.texts_to_sequences(x_validation)\n",
    "x_val_seq = pad_sequences(sequences_val, maxlen=45)\n",
    "num_words = 100000\n",
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 07:32:35.463746 15064 deprecation_wrapper.py:119] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0818 07:32:35.880815 15064 deprecation_wrapper.py:119] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0818 07:32:35.956517 15064 deprecation_wrapper.py:119] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0818 07:32:36.059191 15064 deprecation_wrapper.py:119] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0818 07:32:36.074155 15064 deprecation_wrapper.py:119] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0818 07:32:36.229834 15064 deprecation.py:323] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0818 07:32:36.295741 15064 deprecation_wrapper.py:119] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3675 samples, validate on 787 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 0.9525 - acc: 0.6120 - val_loss: 0.8348 - val_acc: 0.6417\n",
      "Epoch 2/5\n",
      " - 14s - loss: 0.5946 - acc: 0.7671 - val_loss: 0.7706 - val_acc: 0.6925\n",
      "Epoch 3/5\n",
      " - 14s - loss: 0.1957 - acc: 0.9478 - val_loss: 0.8482 - val_acc: 0.6645\n",
      "Epoch 4/5\n",
      " - 14s - loss: 0.0664 - acc: 0.9839 - val_loss: 0.9327 - val_acc: 0.6709\n",
      "Epoch 5/5\n",
      " - 14s - loss: 0.0452 - acc: 0.9886 - val_loss: 1.0299 - val_acc: 0.6595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b943619f60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ptw2v = Sequential()\n",
    "e = Embedding(100000, 200, input_length=45)\n",
    "model_ptw2v.add(e)\n",
    "model_ptw2v.add(Flatten())\n",
    "model_ptw2v.add(Dense(512, activation='relu'))\n",
    "model_ptw2v.add(Dense(10, activation='softmax'))\n",
    "model_ptw2v.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 07:33:50.700862 15064 deprecation.py:506] From C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 45)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 45, 200)      20000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 44, 100)      40100       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 43, 100)      60100       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 42, 100)      80100       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 100)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          154112      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           5130        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10)           0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,339,542\n",
      "Trainable params: 20,339,542\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tweet_input = Input(shape=(45,), dtype='int32')\n",
    "\n",
    "tweet_encoder = Embedding(100000, 200, input_length=45)(tweet_input)\n",
    "bigram_branch = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "trigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "fourgram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "\n",
    "merged = Dense(512, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(10)(merged)\n",
    "output = Activation('softmax')(merged)\n",
    "model = Model(inputs=[tweet_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3675 samples, validate on 787 samples\n",
      "Epoch 1/5\n",
      "3675/3675 [==============================] - ETA: 1:18 - loss: 2.3267 - acc: 0.0000e+0 - ETA: 44s - loss: 2.2586 - acc: 0.3047    - ETA: 33s - loss: 2.1899 - acc: 0.40 - ETA: 28s - loss: 2.1183 - acc: 0.47 - ETA: 24s - loss: 2.0358 - acc: 0.51 - ETA: 22s - loss: 1.9503 - acc: 0.54 - ETA: 20s - loss: 1.8917 - acc: 0.54 - ETA: 18s - loss: 1.8141 - acc: 0.55 - ETA: 17s - loss: 1.7418 - acc: 0.56 - ETA: 17s - loss: 1.6656 - acc: 0.57 - ETA: 16s - loss: 1.5980 - acc: 0.58 - ETA: 15s - loss: 1.5625 - acc: 0.57 - ETA: 14s - loss: 1.5207 - acc: 0.58 - ETA: 14s - loss: 1.4788 - acc: 0.58 - ETA: 13s - loss: 1.4389 - acc: 0.59 - ETA: 13s - loss: 1.4202 - acc: 0.58 - ETA: 12s - loss: 1.4068 - acc: 0.58 - ETA: 12s - loss: 1.3838 - acc: 0.57 - ETA: 11s - loss: 1.3543 - acc: 0.57 - ETA: 11s - loss: 1.3347 - acc: 0.56 - ETA: 11s - loss: 1.3191 - acc: 0.56 - ETA: 10s - loss: 1.2952 - acc: 0.56 - ETA: 10s - loss: 1.2794 - acc: 0.57 - ETA: 9s - loss: 1.2722 - acc: 0.5697 - ETA: 9s - loss: 1.2567 - acc: 0.573 - ETA: 9s - loss: 1.2434 - acc: 0.575 - ETA: 8s - loss: 1.2291 - acc: 0.578 - ETA: 8s - loss: 1.2160 - acc: 0.581 - ETA: 8s - loss: 1.2055 - acc: 0.583 - ETA: 7s - loss: 1.1922 - acc: 0.587 - ETA: 7s - loss: 1.1848 - acc: 0.588 - ETA: 7s - loss: 1.1767 - acc: 0.589 - ETA: 6s - loss: 1.1703 - acc: 0.586 - ETA: 6s - loss: 1.1613 - acc: 0.588 - ETA: 6s - loss: 1.1547 - acc: 0.587 - ETA: 6s - loss: 1.1528 - acc: 0.586 - ETA: 5s - loss: 1.1479 - acc: 0.584 - ETA: 5s - loss: 1.1407 - acc: 0.585 - ETA: 5s - loss: 1.1332 - acc: 0.588 - ETA: 4s - loss: 1.1280 - acc: 0.591 - ETA: 4s - loss: 1.1227 - acc: 0.591 - ETA: 4s - loss: 1.1158 - acc: 0.594 - ETA: 3s - loss: 1.1104 - acc: 0.593 - ETA: 3s - loss: 1.1044 - acc: 0.595 - ETA: 3s - loss: 1.1006 - acc: 0.596 - ETA: 3s - loss: 1.1008 - acc: 0.594 - ETA: 2s - loss: 1.0970 - acc: 0.595 - ETA: 2s - loss: 1.0909 - acc: 0.598 - ETA: 2s - loss: 1.0879 - acc: 0.597 - ETA: 1s - loss: 1.0826 - acc: 0.599 - ETA: 1s - loss: 1.0781 - acc: 0.601 - ETA: 1s - loss: 1.0749 - acc: 0.601 - ETA: 1s - loss: 1.0703 - acc: 0.603 - ETA: 0s - loss: 1.0654 - acc: 0.604 - ETA: 0s - loss: 1.0635 - acc: 0.603 - ETA: 0s - loss: 1.0607 - acc: 0.602 - ETA: 0s - loss: 1.0581 - acc: 0.602 - 15s 4ms/step - loss: 1.0574 - acc: 0.6022 - val_loss: 0.8426 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63787, saving model to CNN_best_weights.01-0.64.hdf5\n",
      "Epoch 2/5\n",
      "3675/3675 [==============================] - ETA: 14s - loss: 0.7628 - acc: 0.67 - ETA: 13s - loss: 0.7958 - acc: 0.67 - ETA: 13s - loss: 0.7859 - acc: 0.67 - ETA: 12s - loss: 0.8117 - acc: 0.64 - ETA: 12s - loss: 0.8133 - acc: 0.65 - ETA: 12s - loss: 0.8197 - acc: 0.64 - ETA: 12s - loss: 0.8153 - acc: 0.64 - ETA: 11s - loss: 0.8202 - acc: 0.65 - ETA: 11s - loss: 0.8361 - acc: 0.64 - ETA: 11s - loss: 0.8530 - acc: 0.63 - ETA: 11s - loss: 0.8527 - acc: 0.63 - ETA: 10s - loss: 0.8592 - acc: 0.62 - ETA: 10s - loss: 0.8619 - acc: 0.62 - ETA: 10s - loss: 0.8531 - acc: 0.62 - ETA: 10s - loss: 0.8563 - acc: 0.62 - ETA: 9s - loss: 0.8635 - acc: 0.6201 - ETA: 9s - loss: 0.8582 - acc: 0.626 - ETA: 9s - loss: 0.8564 - acc: 0.628 - ETA: 9s - loss: 0.8525 - acc: 0.631 - ETA: 8s - loss: 0.8519 - acc: 0.629 - ETA: 8s - loss: 0.8480 - acc: 0.631 - ETA: 8s - loss: 0.8416 - acc: 0.635 - ETA: 8s - loss: 0.8414 - acc: 0.633 - ETA: 7s - loss: 0.8408 - acc: 0.635 - ETA: 7s - loss: 0.8375 - acc: 0.637 - ETA: 7s - loss: 0.8364 - acc: 0.636 - ETA: 7s - loss: 0.8370 - acc: 0.637 - ETA: 6s - loss: 0.8313 - acc: 0.641 - ETA: 6s - loss: 0.8281 - acc: 0.644 - ETA: 6s - loss: 0.8270 - acc: 0.645 - ETA: 6s - loss: 0.8195 - acc: 0.651 - ETA: 6s - loss: 0.8223 - acc: 0.650 - ETA: 5s - loss: 0.8197 - acc: 0.652 - ETA: 5s - loss: 0.8204 - acc: 0.651 - ETA: 5s - loss: 0.8207 - acc: 0.652 - ETA: 5s - loss: 0.8164 - acc: 0.654 - ETA: 4s - loss: 0.8139 - acc: 0.653 - ETA: 4s - loss: 0.8115 - acc: 0.655 - ETA: 4s - loss: 0.8121 - acc: 0.653 - ETA: 4s - loss: 0.8115 - acc: 0.652 - ETA: 3s - loss: 0.8085 - acc: 0.655 - ETA: 3s - loss: 0.8065 - acc: 0.657 - ETA: 3s - loss: 0.8033 - acc: 0.659 - ETA: 3s - loss: 0.8030 - acc: 0.659 - ETA: 3s - loss: 0.7995 - acc: 0.661 - ETA: 2s - loss: 0.7987 - acc: 0.662 - ETA: 2s - loss: 0.7957 - acc: 0.665 - ETA: 2s - loss: 0.7926 - acc: 0.667 - ETA: 2s - loss: 0.7913 - acc: 0.667 - ETA: 1s - loss: 0.7876 - acc: 0.669 - ETA: 1s - loss: 0.7894 - acc: 0.667 - ETA: 1s - loss: 0.7863 - acc: 0.670 - ETA: 1s - loss: 0.7859 - acc: 0.670 - ETA: 0s - loss: 0.7859 - acc: 0.670 - ETA: 0s - loss: 0.7828 - acc: 0.671 - ETA: 0s - loss: 0.7818 - acc: 0.673 - ETA: 0s - loss: 0.7781 - acc: 0.674 - 14s 4ms/step - loss: 0.7784 - acc: 0.6735 - val_loss: 0.7293 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63787 to 0.70013, saving model to CNN_best_weights.02-0.70.hdf5\n",
      "Epoch 3/5\n",
      "3675/3675 [==============================] - ETA: 15s - loss: 0.5200 - acc: 0.82 - ETA: 13s - loss: 0.5181 - acc: 0.82 - ETA: 13s - loss: 0.5059 - acc: 0.82 - ETA: 13s - loss: 0.5204 - acc: 0.79 - ETA: 13s - loss: 0.4884 - acc: 0.80 - ETA: 12s - loss: 0.4823 - acc: 0.80 - ETA: 12s - loss: 0.4729 - acc: 0.80 - ETA: 12s - loss: 0.4785 - acc: 0.80 - ETA: 11s - loss: 0.4823 - acc: 0.80 - ETA: 11s - loss: 0.4828 - acc: 0.80 - ETA: 11s - loss: 0.4938 - acc: 0.80 - ETA: 11s - loss: 0.4992 - acc: 0.80 - ETA: 10s - loss: 0.4940 - acc: 0.80 - ETA: 10s - loss: 0.4938 - acc: 0.80 - ETA: 10s - loss: 0.4881 - acc: 0.80 - ETA: 10s - loss: 0.4847 - acc: 0.80 - ETA: 9s - loss: 0.4805 - acc: 0.8061 - ETA: 9s - loss: 0.4886 - acc: 0.802 - ETA: 9s - loss: 0.4908 - acc: 0.801 - ETA: 9s - loss: 0.4898 - acc: 0.803 - ETA: 8s - loss: 0.4891 - acc: 0.805 - ETA: 8s - loss: 0.4881 - acc: 0.804 - ETA: 8s - loss: 0.4859 - acc: 0.805 - ETA: 8s - loss: 0.4834 - acc: 0.804 - ETA: 7s - loss: 0.4839 - acc: 0.803 - ETA: 7s - loss: 0.4878 - acc: 0.803 - ETA: 7s - loss: 0.4877 - acc: 0.803 - ETA: 7s - loss: 0.4909 - acc: 0.801 - ETA: 6s - loss: 0.4869 - acc: 0.803 - ETA: 6s - loss: 0.4846 - acc: 0.804 - ETA: 6s - loss: 0.4871 - acc: 0.804 - ETA: 6s - loss: 0.4844 - acc: 0.806 - ETA: 5s - loss: 0.4835 - acc: 0.806 - ETA: 5s - loss: 0.4831 - acc: 0.806 - ETA: 5s - loss: 0.4797 - acc: 0.807 - ETA: 5s - loss: 0.4765 - acc: 0.808 - ETA: 4s - loss: 0.4763 - acc: 0.808 - ETA: 4s - loss: 0.4741 - acc: 0.808 - ETA: 4s - loss: 0.4687 - acc: 0.810 - ETA: 4s - loss: 0.4699 - acc: 0.809 - ETA: 4s - loss: 0.4677 - acc: 0.810 - ETA: 3s - loss: 0.4679 - acc: 0.811 - ETA: 3s - loss: 0.4689 - acc: 0.810 - ETA: 3s - loss: 0.4683 - acc: 0.811 - ETA: 3s - loss: 0.4669 - acc: 0.812 - ETA: 2s - loss: 0.4688 - acc: 0.812 - ETA: 2s - loss: 0.4673 - acc: 0.813 - ETA: 2s - loss: 0.4693 - acc: 0.812 - ETA: 2s - loss: 0.4688 - acc: 0.812 - ETA: 1s - loss: 0.4672 - acc: 0.812 - ETA: 1s - loss: 0.4635 - acc: 0.815 - ETA: 1s - loss: 0.4639 - acc: 0.814 - ETA: 1s - loss: 0.4636 - acc: 0.814 - ETA: 0s - loss: 0.4680 - acc: 0.813 - ETA: 0s - loss: 0.4665 - acc: 0.815 - ETA: 0s - loss: 0.4663 - acc: 0.815 - ETA: 0s - loss: 0.4641 - acc: 0.815 - 14s 4ms/step - loss: 0.4637 - acc: 0.8161 - val_loss: 0.8020 - val_acc: 0.6569\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.70013\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3675/3675 [==============================] - ETA: 14s - loss: 0.2098 - acc: 0.95 - ETA: 13s - loss: 0.1976 - acc: 0.95 - ETA: 13s - loss: 0.1830 - acc: 0.96 - ETA: 14s - loss: 0.1937 - acc: 0.96 - ETA: 13s - loss: 0.1983 - acc: 0.95 - ETA: 13s - loss: 0.2089 - acc: 0.94 - ETA: 13s - loss: 0.2062 - acc: 0.93 - ETA: 13s - loss: 0.2103 - acc: 0.93 - ETA: 12s - loss: 0.2074 - acc: 0.93 - ETA: 12s - loss: 0.2078 - acc: 0.93 - ETA: 12s - loss: 0.2156 - acc: 0.93 - ETA: 11s - loss: 0.2099 - acc: 0.93 - ETA: 11s - loss: 0.2076 - acc: 0.93 - ETA: 11s - loss: 0.2078 - acc: 0.93 - ETA: 11s - loss: 0.2141 - acc: 0.93 - ETA: 10s - loss: 0.2175 - acc: 0.93 - ETA: 10s - loss: 0.2172 - acc: 0.93 - ETA: 10s - loss: 0.2171 - acc: 0.93 - ETA: 9s - loss: 0.2212 - acc: 0.9326 - ETA: 9s - loss: 0.2198 - acc: 0.933 - ETA: 9s - loss: 0.2181 - acc: 0.934 - ETA: 9s - loss: 0.2147 - acc: 0.936 - ETA: 8s - loss: 0.2107 - acc: 0.938 - ETA: 8s - loss: 0.2108 - acc: 0.938 - ETA: 8s - loss: 0.2094 - acc: 0.938 - ETA: 8s - loss: 0.2114 - acc: 0.937 - ETA: 7s - loss: 0.2124 - acc: 0.936 - ETA: 7s - loss: 0.2121 - acc: 0.936 - ETA: 7s - loss: 0.2075 - acc: 0.938 - ETA: 6s - loss: 0.2044 - acc: 0.940 - ETA: 6s - loss: 0.2027 - acc: 0.941 - ETA: 6s - loss: 0.2007 - acc: 0.941 - ETA: 6s - loss: 0.2016 - acc: 0.940 - ETA: 5s - loss: 0.2024 - acc: 0.939 - ETA: 5s - loss: 0.1993 - acc: 0.941 - ETA: 5s - loss: 0.1975 - acc: 0.942 - ETA: 5s - loss: 0.1984 - acc: 0.942 - ETA: 4s - loss: 0.1972 - acc: 0.942 - ETA: 4s - loss: 0.2002 - acc: 0.941 - ETA: 4s - loss: 0.1981 - acc: 0.942 - ETA: 4s - loss: 0.1982 - acc: 0.941 - ETA: 3s - loss: 0.1971 - acc: 0.942 - ETA: 3s - loss: 0.1963 - acc: 0.943 - ETA: 3s - loss: 0.1959 - acc: 0.943 - ETA: 3s - loss: 0.1957 - acc: 0.942 - ETA: 2s - loss: 0.1934 - acc: 0.943 - ETA: 2s - loss: 0.1926 - acc: 0.943 - ETA: 2s - loss: 0.1916 - acc: 0.943 - ETA: 2s - loss: 0.1912 - acc: 0.943 - ETA: 1s - loss: 0.1910 - acc: 0.943 - ETA: 1s - loss: 0.1922 - acc: 0.942 - ETA: 1s - loss: 0.1940 - acc: 0.942 - ETA: 1s - loss: 0.1939 - acc: 0.941 - ETA: 0s - loss: 0.1923 - acc: 0.942 - ETA: 0s - loss: 0.1913 - acc: 0.943 - ETA: 0s - loss: 0.1895 - acc: 0.943 - ETA: 0s - loss: 0.1912 - acc: 0.943 - 15s 4ms/step - loss: 0.1911 - acc: 0.9431 - val_loss: 0.9603 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.70013\n",
      "Epoch 5/5\n",
      "3675/3675 [==============================] - ETA: 14s - loss: 0.0561 - acc: 1.00 - ETA: 16s - loss: 0.1050 - acc: 0.99 - ETA: 15s - loss: 0.0966 - acc: 0.98 - ETA: 15s - loss: 0.0827 - acc: 0.99 - ETA: 14s - loss: 0.0804 - acc: 0.99 - ETA: 14s - loss: 0.0737 - acc: 0.99 - ETA: 14s - loss: 0.0711 - acc: 0.99 - ETA: 13s - loss: 0.0674 - acc: 0.99 - ETA: 13s - loss: 0.0730 - acc: 0.99 - ETA: 12s - loss: 0.0697 - acc: 0.99 - ETA: 12s - loss: 0.0692 - acc: 0.99 - ETA: 12s - loss: 0.0746 - acc: 0.98 - ETA: 11s - loss: 0.0861 - acc: 0.98 - ETA: 11s - loss: 0.0813 - acc: 0.98 - ETA: 11s - loss: 0.0812 - acc: 0.98 - ETA: 10s - loss: 0.0781 - acc: 0.98 - ETA: 10s - loss: 0.0754 - acc: 0.98 - ETA: 10s - loss: 0.0732 - acc: 0.98 - ETA: 10s - loss: 0.0714 - acc: 0.98 - ETA: 9s - loss: 0.0702 - acc: 0.9867 - ETA: 9s - loss: 0.0702 - acc: 0.985 - ETA: 9s - loss: 0.0741 - acc: 0.985 - ETA: 9s - loss: 0.0743 - acc: 0.985 - ETA: 8s - loss: 0.0732 - acc: 0.985 - ETA: 8s - loss: 0.0713 - acc: 0.985 - ETA: 8s - loss: 0.0696 - acc: 0.986 - ETA: 8s - loss: 0.0692 - acc: 0.986 - ETA: 7s - loss: 0.0719 - acc: 0.985 - ETA: 7s - loss: 0.0706 - acc: 0.986 - ETA: 7s - loss: 0.0689 - acc: 0.986 - ETA: 7s - loss: 0.0714 - acc: 0.985 - ETA: 6s - loss: 0.0720 - acc: 0.985 - ETA: 6s - loss: 0.0716 - acc: 0.985 - ETA: 6s - loss: 0.0764 - acc: 0.983 - ETA: 6s - loss: 0.0762 - acc: 0.983 - ETA: 5s - loss: 0.0770 - acc: 0.983 - ETA: 5s - loss: 0.0756 - acc: 0.983 - ETA: 5s - loss: 0.0751 - acc: 0.983 - ETA: 4s - loss: 0.0767 - acc: 0.982 - ETA: 4s - loss: 0.0779 - acc: 0.982 - ETA: 4s - loss: 0.0767 - acc: 0.982 - ETA: 4s - loss: 0.0777 - acc: 0.981 - ETA: 3s - loss: 0.0768 - acc: 0.982 - ETA: 3s - loss: 0.0768 - acc: 0.982 - ETA: 3s - loss: 0.0763 - acc: 0.982 - ETA: 3s - loss: 0.0774 - acc: 0.982 - ETA: 2s - loss: 0.0786 - acc: 0.981 - ETA: 2s - loss: 0.0780 - acc: 0.981 - ETA: 2s - loss: 0.0774 - acc: 0.981 - ETA: 1s - loss: 0.0770 - acc: 0.981 - ETA: 1s - loss: 0.0759 - acc: 0.981 - ETA: 1s - loss: 0.0762 - acc: 0.982 - ETA: 1s - loss: 0.0765 - acc: 0.981 - ETA: 0s - loss: 0.0764 - acc: 0.981 - ETA: 0s - loss: 0.0773 - acc: 0.981 - ETA: 0s - loss: 0.0765 - acc: 0.981 - ETA: 0s - loss: 0.0763 - acc: 0.981 - 15s 4ms/step - loss: 0.0764 - acc: 0.9818 - val_loss: 1.0335 - val_acc: 0.6645\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.70013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b942498ba8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"CNN_best_weights.{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit(x_train_seq, y_train, batch_size=64, epochs=5,\n",
    "                     validation_data=(x_val_seq, y_validation), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus FX504\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer(max_features=100000,ngram_range=(1, 3))\n",
    "tvec.fit(x_train)\n",
    "\n",
    "x_train_tfidf = tvec.transform(x_train)\n",
    "x_test_tfidf = tvec.transform(x_test)\n",
    "lr_with_tfidf = LogisticRegression()\n",
    "lr_with_tfidf.fit(x_train_tfidf,y_train)\n",
    "lr_with_tfidf.score(x_test_tfidf,y_test)\n",
    "yhat_lr = lr_with_tfidf.predict_proba(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_CNN_model = load_model('CNN_best_weights.02-0.70.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788/788 [==============================] - ETA:  - ETA:  - ETA:  - 0s 300us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7598611273741359, 0.6916243651796719]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_CNN_model.evaluate(x=x_test_seq, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = loaded_CNN_model.predict(x_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "n_classes=3\n",
    "y = label_binarize(y_test, classes=[0,1,2])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:, i], yhat_cnn[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test DataSet Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Reading Test Dataset\n",
    "def read_data(tweets_data_path):\n",
    "    tweets_data = []\n",
    "    tweets_file = open(tweets_data_path, \"r\")\n",
    "    line = tweets_file.readline()\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue\n",
    "    data = pd.DataFrame.from_dict(tweets_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Test Dataset\n",
    "tweet_data=read_data(\"D:/Thesis/autonomousDriveMulti.json\")\n",
    "tweet_data1=read_data(\"D:/Thesis/autonomousDrive.json\")\n",
    "tweet_data2=read_data(\"D:/Thesis/python.json\")\n",
    "tweets= pd.concat([tweet_data, tweet_data1,tweet_data2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test Dataset Only\n",
    "tweets_by_lang = tweets['lang'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Languages', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n",
    "tweets_by_lang[:5].plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test Dataset Only\n",
    "tweets_by_lang = tweets['source'].value_counts()\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Source', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n",
    "tweets_by_lang[:5].plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_data_path = 'D:/Thesis/autonomousDrive.json'\n",
    "\n",
    "#tweets_data = []\n",
    "#tweets_file = open(tweets_data_path, \"r\")\n",
    "#line = tweets_file.readline()\n",
    "#for line in tweets_file:\n",
    "#    try:\n",
    "#        tweet = json.loads(line)\n",
    "#        tweets_data.append(tweet)\n",
    "#    except:\n",
    "#        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = pd.DataFrame.from_dict(tweets_data)\n",
    "#tweets = pd.read_excel(\"D:\\\\Thesis\\\\Code\\\\tweet.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion to xlsx (optional)\n",
    "writer = ExcelWriter('tweet.xlsx')\n",
    "tweets.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test Dataset Only\n",
    "tweets['created_at'] = pd.to_datetime(tweets.created_at)\n",
    "tweets['source'] = tweets['source'].str.extract('>(.+?)<', expand=False).str.strip()\n",
    "tweets['pre_clean_len'] = [len(t) for t in tweets.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test Dataset Only\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.boxplot(tweets.pre_clean_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data Clean\n",
    "x = len(tweets.index)\n",
    "nums = [0,x]\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%881 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(tweets['text'][i]))\n",
    "    clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(message for message in tweets.text)\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(width = 2400, height = 1600).generate(text)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='gaussian')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_len=pd.Series(data=tweets['pre_clean_len'].values, index=tweets['created_at'])\n",
    "time_len.plot(figsize=(16, 4), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df.groupby(level=0).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
